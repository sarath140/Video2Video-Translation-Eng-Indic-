{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QGjmTXXbJFF5",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/AI4Bharat/IndicTrans2\n",
        "%cd IndicTrans2/huggingface_interface"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash install.sh"
      ],
      "metadata": {
        "id": "sWmQExzOwlTK",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from google.colab import drive\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from IndicTransToolkit.IndicTransToolkit import IndicProcessor\n",
        "\n",
        "# ========================\n",
        "# Utility Functions\n",
        "# ========================\n",
        "\n",
        "def format_timestamp(seconds: float) -> str:\n",
        "    \"\"\"Preserve SRT timestamp format.\"\"\"\n",
        "    millis = int((seconds - int(seconds)) * 1000)\n",
        "    seconds = int(seconds)\n",
        "    mins, sec = divmod(seconds, 60)\n",
        "    hrs, mins = divmod(mins, 60)\n",
        "    return f\"{hrs:02d}:{mins:02d}:{sec:02d},{millis:03d}\"\n",
        "\n",
        "# ========================\n",
        "# Environment Setup\n",
        "# ========================\n",
        "\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "src_lang = \"eng_Latn\"\n",
        "tgt_lang = \"hin_Deva\"\n",
        "model_name = \"ai4bharat/indictrans2-en-indic-1B\"\n",
        "\n",
        "# Load model + tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name, trust_remote_code=True)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
        "    model_name,\n",
        "    trust_remote_code=True,\n",
        "    torch_dtype=torch.float16,\n",
        "    attn_implementation=\"flash_attention_2\"\n",
        ").to(DEVICE)\n",
        "\n",
        "ip = IndicProcessor(inference=True)\n",
        "\n",
        "# Input / Output paths\n",
        "input_dir = \"/content/drive/MyDrive/Commercial Horticulture English ASR\"\n",
        "output_dir = \"/content/drive/MyDrive/Commercial Horticulture English MThi\"\n",
        "\n",
        "# ========================\n",
        "# Translation Logic\n",
        "# ========================\n",
        "\n",
        "def translate_srt(input_path, output_srt, output_txt):\n",
        "    \"\"\"Translate a single SRT file and save both .srt and .txt outputs.\"\"\"\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        srt_lines = f.readlines()\n",
        "\n",
        "    translated_srt, translated_txt = [], []\n",
        "\n",
        "    for i, line in enumerate(srt_lines):\n",
        "        if i % 4 == 2:  # Subtitle line\n",
        "            text = line.strip()\n",
        "            if text:\n",
        "                batch = ip.preprocess_batch([text], src_lang=src_lang, tgt_lang=tgt_lang)\n",
        "                inputs = tokenizer(batch, truncation=True, padding=\"longest\", return_tensors=\"pt\").to(DEVICE)\n",
        "\n",
        "                with torch.no_grad():\n",
        "                    outputs = model.generate(\n",
        "                        **inputs,\n",
        "                        max_length=256,\n",
        "                        num_beams=5,\n",
        "                        num_return_sequences=1,\n",
        "                    )\n",
        "\n",
        "                decoded = tokenizer.batch_decode(outputs, skip_special_tokens=True)[0]\n",
        "                final_text = ip.postprocess_batch([decoded], lang=tgt_lang)[0]\n",
        "\n",
        "                translated_srt.append(final_text)\n",
        "                translated_txt.append(final_text)\n",
        "        else:\n",
        "            translated_srt.append(line.strip())\n",
        "\n",
        "    # Save outputs\n",
        "    with open(output_srt, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(translated_srt))\n",
        "\n",
        "    with open(output_txt, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(translated_txt))\n",
        "\n",
        "    print(f\"âœ… Saved: {output_srt}\")\n",
        "    print(f\"âœ… Saved: {output_txt}\")\n",
        "\n",
        "# ========================\n",
        "# Batch Processing\n",
        "# ========================\n",
        "\n",
        "for root, _, files in os.walk(input_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".srt\"):\n",
        "            input_path = os.path.join(root, file)\n",
        "            relative = os.path.relpath(root, input_dir)\n",
        "            save_dir = os.path.join(output_dir, relative)\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "            output_srt = os.path.join(save_dir, file)\n",
        "            output_txt = os.path.join(save_dir, file.replace(\".srt\", \".txt\"))\n",
        "\n",
        "            print(f\"ðŸ”„ Translating: {input_path}\")\n",
        "            translate_srt(input_path, output_srt, output_txt)\n"
      ],
      "metadata": {
        "id": "H6A5pzK4yY7a",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}