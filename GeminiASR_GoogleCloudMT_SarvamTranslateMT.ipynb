{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# GeminiASR"
      ],
      "metadata": {
        "id": "sgI7t2DUFRRR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ========================\n",
        "# INSTALL & IMPORTS\n",
        "# ========================\n",
        "!pip install -q google-generativeai pydub tqdm librosa\n",
        "\n",
        "import os\n",
        "import io\n",
        "from google.colab import drive, userdata\n",
        "import google.generativeai as genai\n",
        "from pydub import AudioSegment\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ========================\n",
        "# SETUP\n",
        "# ========================\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Securely load your Gemini API key from Colab secrets\n",
        "api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "if not api_key:\n",
        "    raise ValueError(\"‚ùå No GOOGLE_API_KEY found in Colab secrets! Add it under 'More ‚Üí Secrets'.\")\n",
        "\n",
        "genai.configure(api_key=api_key)\n",
        "\n",
        "# Choose your model\n",
        "model = genai.GenerativeModel(\"models/gemini-2.5-pro\")\n",
        "\n",
        "# Input/output folders in Google Drive\n",
        "input_dir = \"/content/drive/MyDrive/a/\"\n",
        "output_dir = os.path.join(input_dir, \"transcripts_withsrt_nofill\")\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "# ========================\n",
        "# HELPER FUNCTIONS\n",
        "# ========================\n",
        "\n",
        "def transcribe_audio_file(file_path):\n",
        "    \"\"\"Transcribe full audio file without splitting.\"\"\"\n",
        "    audio = AudioSegment.from_wav(file_path)\n",
        "    buffer = io.BytesIO()\n",
        "    audio.export(buffer, format=\"wav\")\n",
        "    audio_bytes = buffer.getvalue()\n",
        "\n",
        "    try:\n",
        "        response = model.generate_content([\n",
        "            {\"mime_type\": \"audio/wav\", \"data\": audio_bytes},\n",
        "            \"\"\"\n",
        "            Transcribe this audio exactly as spoken (no extra comments, no filler words) with the following .srt format:\n",
        "\n",
        "            1\n",
        "            00:00:15,362 --> 00:00:21,789\n",
        "            ‡§Ö‡§¨ ‡§π‡§Æ ‡§ú‡§æ‡§®‡•á‡§Ç‡§ó‡•á ‡§ï‡•à‡§Ç‡§°‡§≤‡•ç‡§∏ ‡§Æ‡•á‡§Ç ‡§ï‡•ç‡§Ø‡§æ ‡§ï‡•ç‡§Ø‡§æ ‡§ö‡•Ä‡§ú‡§º‡•ã‡§Ç ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§™‡§°‡§º‡§§‡•Ä ‡§π‡•à ‡§î‡§∞ ‡§â‡§®‡§ï‡•ã ‡§π‡§Æ ‡§ï‡§π‡§æ‡§Å ‡§∏‡•á ‡§ñ‡§º‡§∞‡•Ä‡§¶ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç\n",
        "\n",
        "            2\n",
        "            00:00:21,922 --> 00:00:27,422\n",
        "            ‡§§‡•ã ‡§∏‡§¨‡§∏‡•á ‡§™‡§π‡§≤‡•á ‡§ï‡•à‡§Ç‡§°‡§≤ ‡§¨‡§®‡§æ‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡§Æ‡•á‡§Ç ‡§°‡§¨‡§≤ ‡§¨‡•â‡§Ø‡§≤‡§∞ ‡§ï‡•Ä ‡§ú‡§º‡§∞‡•Ç‡§∞‡§§ ‡§™‡§°‡§º‡§§‡•Ä ‡§π‡•à ‡§Ø‡•á\n",
        "\n",
        "            3\n",
        "            00:00:27,617 --> 00:00:29,853\n",
        "            ‡§á‡§∏ ‡§§‡§∞‡§π ‡§ï‡§æ ‡§Ø‡•á ‡§á‡§Ç‡§°‡§ï‡•ç‡§∂‡§® ‡§π‡•à\n",
        "\n",
        "            and so on...\n",
        "\n",
        "            The transcription should strictly follow the format above, where:\n",
        "            - **Timestamps** are in the format of HH:MM:SS,SSS --> HH:MM:SS,SSS (with millisecond precision).\n",
        "            - Each entry should have a **sequential index** starting from 1 (e.g., 1, 2, 3, ...).\n",
        "            - The spoken text should be captured **exactly as it is spoken**, without adding or removing words(but remove filler words).\n",
        "            - If there is **silence** or a pause, mark the duration with a timestamp like this:\n",
        "              ```\n",
        "              4\n",
        "              00:00:29,854 --> 00:00:34,500\n",
        "              [Silence]\n",
        "              ```\n",
        "            - Include **Speaker labels** (e.g., Speaker 1, Speaker 2) where relevant if multiple speakers are detected.\n",
        "\n",
        "            Please ensure the output strictly follows this format. Thank you!\n",
        "            \"\"\"\n",
        "        ])\n",
        "\n",
        "        return response.text.strip()\n",
        "    except Exception as e:\n",
        "        print(\"‚ùå Error:\", e)\n",
        "        return \"\"\n",
        "\n",
        "# ========================\n",
        "# MAIN PROCESS\n",
        "# ========================\n",
        "\n",
        "for filename in os.listdir(input_dir):\n",
        "    if filename.lower().endswith(\".wav\"):\n",
        "        file_path = os.path.join(input_dir, filename)\n",
        "        print(f\"\\nüéß Transcribing full audio: {filename}\")\n",
        "\n",
        "        # Get full transcription\n",
        "        text = transcribe_audio_file(file_path)\n",
        "\n",
        "        # Save TXT file\n",
        "        txt_output = os.path.join(output_dir, filename.replace(\".wav\", \".txt\"))\n",
        "        with open(txt_output, \"w\", encoding=\"utf-8\") as f:\n",
        "            f.write(text)\n",
        "\n",
        "        print(f\"‚úÖ Done: {filename}\")\n",
        "        print(f\"üìÑ TXT saved to: {txt_output}\")\n"
      ],
      "metadata": {
        "id": "Uyt_mLjPFQ9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GoogleCloudMT"
      ],
      "metadata": {
        "id": "PLvriD1MFMNM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.cloud import translate_v2 as translate\n",
        "import os\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the environment variable for your Google Cloud credentials\n",
        "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = '/content/drive/MyDrive/Apikey/gen-lang-client-05.json'\n",
        "\n",
        "# Initialize Google Cloud Translate client\n",
        "translate_client = translate.Client()\n",
        "\n",
        "# Function to translate text using Google Translate\n",
        "def translate_text(text, target_language='te'):\n",
        "    result = translate_client.translate(text, target_language=target_language)\n",
        "    return result['translatedText']\n",
        "\n",
        "# Function to translate a .srt file\n",
        "def translate_srt(input_file_path, output_file_path, target_language='te'):\n",
        "    # Read the .srt file\n",
        "    with open(input_file_path, 'r', encoding='utf-8') as file:\n",
        "        srt_lines = file.readlines()\n",
        "\n",
        "    # Extract subtitle text lines (every 3rd line)\n",
        "    subtitle_lines = []\n",
        "    subtitle_indices = []\n",
        "    for i, line in enumerate(srt_lines):\n",
        "        if i % 4 == 2:  # Every 3rd line is subtitle text in .srt files\n",
        "            subtitle_lines.append(line.strip())\n",
        "            subtitle_indices.append(i)\n",
        "\n",
        "    # Translate subtitle lines in batches\n",
        "    print(f\"üß† Translating {len(subtitle_lines)} subtitle lines from {os.path.basename(input_file_path)}...\")\n",
        "\n",
        "    translated_lines = []\n",
        "    batch_size = 8  # You can adjust the batch size based on your needs\n",
        "\n",
        "    for i in range(0, len(subtitle_lines), batch_size):\n",
        "        batch = subtitle_lines[i:i + batch_size]\n",
        "        translated_batch = [translate_text(text, target_language=target_language) for text in batch]\n",
        "        translated_lines.extend(translated_batch)\n",
        "\n",
        "    # Rebuild the .srt file with translated text\n",
        "    translated_srt = []\n",
        "    t_idx = 0\n",
        "    for i, line in enumerate(srt_lines):\n",
        "        if i in subtitle_indices:\n",
        "            translated_srt.append(translated_lines[t_idx])\n",
        "            t_idx += 1\n",
        "        else:\n",
        "            translated_srt.append(line.strip())\n",
        "\n",
        "    # Save the translated .srt file\n",
        "    with open(output_file_path, 'w', encoding='utf-8') as output_file:\n",
        "        output_file.write(\"\\n\".join(translated_srt))\n",
        "\n",
        "    print(f\"‚úÖ Translation complete! The translated SRT is saved at {output_file_path}\")\n",
        "\n",
        "# Example usage:\n",
        "# Define the path of your input .srt file and output file on Google Drive\n",
        "input_file_path = '/content/drive/MyDrive/a/transcripts_withsrt_nofill/eng/Chapter 6A - Sucessful Entreuprenuer Journey.srt'  # Path to your input .srt file\n",
        "output_file_path = '/content/drive/MyDrive/a/transcripts_withsrt_nofill/eng/MTeng/tel.srt'  # Path to save the translated .srt file\n",
        "\n",
        "# Call the function to translate the .srt file\n",
        "translate_srt(input_file_path, output_file_path, target_language='te')\n"
      ],
      "metadata": {
        "id": "8XnhX9FSFLyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SarvamTranslateMT"
      ],
      "metadata": {
        "id": "eG9wb4LEFI3C"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fKLSm9EEmU0"
      },
      "outputs": [],
      "source": [
        "# ========================\n",
        "# INSTALL & IMPORTS\n",
        "# ========================\n",
        "!pip install transformers accelerate bitsandbytes tqdm -q\n",
        "\n",
        "import os\n",
        "import torch\n",
        "from tqdm import tqdm\n",
        "from google.colab import drive\n",
        "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
        "\n",
        "# ========================\n",
        "# SETUP\n",
        "# ========================\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "\n",
        "model_name = \"sarvamai/sarvam-translate\"\n",
        "tgt_lang = \"Telugu\"  # Change this to \"Hindi\", \"Tamil\", etc.\n",
        "\n",
        "# Load model + tokenizer\n",
        "print(\"‚è≥ Loading model...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    model_name,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float32  # safer for stability\n",
        ")\n",
        "print(\"‚úÖ Model loaded successfully!\")\n",
        "\n",
        "# Input / Output directories\n",
        "input_dir = \"/content/drive/MyDrive/aa\"\n",
        "output_dir = \"/content/drive/MyDrive/aTelugu\"\n",
        "os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "\n",
        "# ========================\n",
        "# TRANSLATION HELPERS\n",
        "# ========================\n",
        "\n",
        "def batch_translate_sarvam(texts, tgt_lang, batch_size=8):\n",
        "    \"\"\"Translate multiple lines at once using Sarvam model.\"\"\"\n",
        "    translations = []\n",
        "\n",
        "    for i in range(0, len(texts), batch_size):\n",
        "        batch = texts[i:i + batch_size]\n",
        "\n",
        "        # Build system + user messages for each text\n",
        "        messages = []\n",
        "        for t in batch:\n",
        "            messages.append([\n",
        "                {\"role\": \"system\", \"content\": f\"Translate the text below to {tgt_lang}.\"},\n",
        "                {\"role\": \"user\", \"content\": t}\n",
        "            ])\n",
        "\n",
        "        # Create prompts\n",
        "        prompts = [\n",
        "            tokenizer.apply_chat_template(m, tokenize=False, add_generation_prompt=True)\n",
        "            for m in messages\n",
        "        ]\n",
        "\n",
        "        # Tokenize as a batch\n",
        "        inputs = tokenizer(\n",
        "            prompts,\n",
        "            return_tensors=\"pt\",\n",
        "            padding=True,\n",
        "            truncation=True,\n",
        "            max_length=1024\n",
        "        ).to(model.device)\n",
        "\n",
        "        # Generate in one go\n",
        "        with torch.no_grad():\n",
        "            outputs = model.generate(\n",
        "                **inputs,\n",
        "                max_new_tokens=256,\n",
        "                do_sample=False,          # deterministic, avoids GPU crash\n",
        "                num_beams=4,\n",
        "                temperature=0.7,\n",
        "                pad_token_id=tokenizer.eos_token_id\n",
        "            )\n",
        "\n",
        "        # Decode each result\n",
        "        for j, out in enumerate(outputs):\n",
        "            gen_ids = out[len(inputs.input_ids[j]):]\n",
        "            text_out = tokenizer.decode(gen_ids, skip_special_tokens=True).strip()\n",
        "            translations.append(text_out if text_out else batch[j])\n",
        "\n",
        "        torch.cuda.empty_cache()  # Free VRAM\n",
        "\n",
        "    return translations\n",
        "\n",
        "\n",
        "def translate_srt(input_path, output_srt, output_txt, tgt_lang):\n",
        "    \"\"\"Translate a single SRT file using batched Sarvam translation.\"\"\"\n",
        "    with open(input_path, 'r', encoding='utf-8') as f:\n",
        "        srt_lines = f.readlines()\n",
        "\n",
        "    translated_srt, translated_txt = [], []\n",
        "    subtitle_lines, subtitle_indices = [], []\n",
        "\n",
        "    # Collect subtitle text lines (every 3rd line)\n",
        "    for i, line in enumerate(srt_lines):\n",
        "        if i % 4 == 2:\n",
        "            text = line.strip()\n",
        "            if text:\n",
        "                subtitle_lines.append(text)\n",
        "                subtitle_indices.append(i)\n",
        "\n",
        "    print(f\"üîÑ Translating {len(subtitle_lines)} lines from {os.path.basename(input_path)}...\")\n",
        "\n",
        "    # Batch translation\n",
        "    translated_lines = []\n",
        "    for batch_start in tqdm(range(0, len(subtitle_lines), 8), desc=\"üöÄ Translating\", ncols=100):\n",
        "        batch = subtitle_lines[batch_start:batch_start + 8]\n",
        "        batch_translated = batch_translate_sarvam(batch, tgt_lang, batch_size=8)\n",
        "        translated_lines.extend(batch_translated)\n",
        "\n",
        "    # Merge translations back into original structure\n",
        "    t_idx = 0\n",
        "    for i, line in enumerate(srt_lines):\n",
        "        if i in subtitle_indices:\n",
        "            translated_srt.append(translated_lines[t_idx])\n",
        "            translated_txt.append(translated_lines[t_idx])\n",
        "            t_idx += 1\n",
        "        else:\n",
        "            translated_srt.append(line.strip())\n",
        "\n",
        "    # Save results\n",
        "    with open(output_srt, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(translated_srt))\n",
        "\n",
        "    with open(output_txt, 'w', encoding='utf-8') as f:\n",
        "        f.write(\"\\n\".join(translated_txt))\n",
        "\n",
        "    print(f\"‚úÖ Saved translated SRT ‚Üí {output_srt}\")\n",
        "    print(f\"‚úÖ Saved plain text ‚Üí {output_txt}\")\n",
        "\n",
        "\n",
        "# ========================\n",
        "# BATCH PROCESSING LOOP\n",
        "# ========================\n",
        "\n",
        "for root, _, files in os.walk(input_dir):\n",
        "    for file in files:\n",
        "        if file.endswith(\".srt\"):\n",
        "            input_path = os.path.join(root, file)\n",
        "            relative = os.path.relpath(root, input_dir)\n",
        "            save_dir = os.path.join(output_dir, relative)\n",
        "            os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "            output_srt = os.path.join(save_dir, file)\n",
        "            output_txt = os.path.join(save_dir, file.replace(\".srt\", \".txt\"))\n",
        "\n",
        "            print(f\"\\nüîÑ Translating: {input_path}\")\n",
        "            translate_srt(input_path, output_srt, output_txt, tgt_lang)\n",
        "            torch.cuda.empty_cache()  # clear after each file\n"
      ]
    }
  ]
}