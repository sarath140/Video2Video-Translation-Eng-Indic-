{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# setup"
      ],
      "metadata": {
        "id": "NtSxQkb42fhY"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "egMjxx4uKEfB"
      },
      "outputs": [],
      "source": [
        "!pip install transformers torchaudio onnx onnxruntime onnxruntime-gpu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get -y install ffmpeg"
      ],
      "metadata": {
        "id": "gpR18VxZgoVp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "import shutil\n",
        "\n",
        "# # Unmount the drive if it is already mounted\n",
        "# if os.path.exists('/content/drive'):\n",
        "#   try:\n",
        "#     drive.flush_and_unmount()\n",
        "#   except ValueError:\n",
        "#     pass # Drive was not mounted\n",
        "#   # Remove the directory if it still exists and is not empty\n",
        "#   if os.path.exists('/content/drive') and os.path.isdir('/content/drive') and os.listdir('/content/drive'):\n",
        "#       print(\"Removing existing /content/drive directory...\")\n",
        "#       shutil.rmtree('/content/drive')\n",
        "\n",
        "\n",
        "# Mount the drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "J_4Q5eAtguLU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# wav single"
      ],
      "metadata": {
        "id": "02jlWP4A2mg0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert MP4 → mono WAV (16 kHz)\n",
        "import os\n",
        "\n",
        "# Path to your Google Drive folder containing MP4 files\n",
        "input_folder =  \"/content/drive/MyDrive/Test Videos/Hindi\"\n",
        "output_folder = \"/content/drive/MyDrive/Test Videos Wav/Hindi_wav\"\n",
        "\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for dirpath, dirnames, filenames in os.walk(input_folder):\n",
        "    for file in filenames:\n",
        "        if file.endswith(\".mp4\"):\n",
        "            input_path = os.path.join(dirpath, file)\n",
        "\n",
        "            # Recreate subfolder structure inside output\n",
        "            relative_path = os.path.relpath(dirpath, input_folder)\n",
        "            output_dir = os.path.join(output_folder, relative_path)\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "            output_path = os.path.join(output_dir, os.path.splitext(file)[0] + \".wav\")\n",
        "\n",
        "            # Convert with ffmpeg\n",
        "            !ffmpeg -y -i \"{input_path}\" -ac 1 -ar 16000 \"{output_path}\"\n",
        "            print(f\"Converted: {output_path}\")"
      ],
      "metadata": {
        "id": "MjGPlifLg2Qm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 lang"
      ],
      "metadata": {
        "id": "Ry6QC8gT2Ztv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "import torchaudio\n",
        "from transformers import AutoModel\n",
        "from pathlib import Path\n",
        "\n",
        "# -------------------------------\n",
        "# Load IndicConformer model\n",
        "# -------------------------------\n",
        "print(\"🔄 Loading IndicConformer model ...\")\n",
        "model = AutoModel.from_pretrained(\n",
        "    \"ai4bharat/indic-conformer-600m-multilingual\", trust_remote_code=True\n",
        ")\n",
        "print(\"✅ Model loaded\\n\")\n",
        "\n",
        "# -------------------------------\n",
        "# Load Silero VAD\n",
        "# -------------------------------\n",
        "print(\"🔄 Loading VAD model ...\")\n",
        "vad_model, utils = torch.hub.load(\n",
        "    repo_or_dir=\"snakers4/silero-vad\", model=\"silero_vad\", force_reload=False\n",
        ")\n",
        "(get_speech_timestamps, save_audio, read_audio, VADIterator, collect_chunks) = utils\n",
        "print(\"✅ VAD loaded\\n\")\n",
        "\n",
        "# -------------------------------\n",
        "# Paths\n",
        "# -------------------------------\n",
        "input_root = \"/content/drive/MyDrive/Test Videos Wav/Hindi_wav\"\n",
        "output_root = \"/content/drive/MyDrive/Test Videos ASR indcnf/Hindi\"\n",
        "os.makedirs(output_root, exist_ok=True)\n",
        "\n",
        "# -------------------------------\n",
        "# Helper: format seconds to SRT time\n",
        "# -------------------------------\n",
        "def format_time(seconds: float):\n",
        "    millis = int((seconds - int(seconds)) * 1000)\n",
        "    h = int(seconds // 3600)\n",
        "    m = int((seconds % 3600) // 60)\n",
        "    s = int(seconds % 60)\n",
        "    return f\"{h:02}:{m:02}:{s:02},{millis:03}\"\n",
        "\n",
        "# -------------------------------\n",
        "# Walk input folder\n",
        "# -------------------------------\n",
        "for root, dirs, files in os.walk(input_root):\n",
        "    for file in files:\n",
        "        if file.lower().endswith(\".wav\"):\n",
        "            input_path = os.path.join(root, file)\n",
        "            print(f\"\\n🎤 Processing: {input_path}\")\n",
        "\n",
        "            # Mirror folder structure inside output_root\n",
        "            rel_path = os.path.relpath(root, input_root)\n",
        "            output_dir = os.path.join(output_root, rel_path)\n",
        "            os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "            base_name = Path(file).stem\n",
        "            txt_path = os.path.join(output_dir, base_name + \".txt\")\n",
        "            srt_path = os.path.join(output_dir, base_name + \".srt\")\n",
        "\n",
        "            # Load and preprocess audio\n",
        "            wav, sr = torchaudio.load(input_path)\n",
        "            wav = torch.mean(wav, dim=0, keepdim=True)  # Convert to mono\n",
        "            if sr != 16000:\n",
        "                wav = torchaudio.transforms.Resample(orig_freq=sr, new_freq=16000)(wav)\n",
        "                sr = 16000\n",
        "\n",
        "            # Normalize audio\n",
        "            wav = wav / torch.max(torch.abs(wav))\n",
        "\n",
        "            # -------------------------------\n",
        "            # Run VAD segmentation\n",
        "            # -------------------------------\n",
        "            speech_timestamps = get_speech_timestamps(\n",
        "                wav[0], vad_model, sampling_rate=sr\n",
        "            )\n",
        "            print(f\"🧩 Detected {len(speech_timestamps)} speech segments.\")\n",
        "\n",
        "            all_text = []\n",
        "\n",
        "            # -------------------------------\n",
        "            # If VAD found segments → process each\n",
        "            # Else → transcribe full file\n",
        "            # -------------------------------\n",
        "            if len(speech_timestamps) > 0:\n",
        "                with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    for i, seg in enumerate(speech_timestamps, start=1):\n",
        "                        start_time = seg[\"start\"] / sr\n",
        "                        end_time = seg[\"end\"] / sr\n",
        "                        segment_wav = wav[:, seg[\"start\"]:seg[\"end\"]]\n",
        "\n",
        "                        result = model(segment_wav, \"hi\", \"ctc\")\n",
        "                        text = result[\"text\"] if isinstance(result, dict) else str(result)\n",
        "                        text = text.strip()\n",
        "\n",
        "                        if text:\n",
        "                            all_text.append(text)\n",
        "                            f.write(\n",
        "                                f\"{i}\\n\"\n",
        "                                f\"{format_time(start_time)} --> {format_time(end_time)}\\n\"\n",
        "                                f\"{text}\\n\\n\"\n",
        "                            )\n",
        "\n",
        "            else:\n",
        "                print(\"⚠️ No speech detected — transcribing full audio...\")\n",
        "                result = model(wav, \"hi\", \"ctc\")\n",
        "                text = result[\"text\"] if isinstance(result, dict) else str(result)\n",
        "                text = text.strip()\n",
        "                all_text.append(text)\n",
        "\n",
        "                # Write single block to SRT\n",
        "                with open(srt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                    f.write(\"1\\n\")\n",
        "                    f.write(f\"00:00:00,000 --> {format_time(len(wav[0])/sr)}\\n\")\n",
        "                    f.write(f\"{text}\\n\\n\")\n",
        "\n",
        "            # -------------------------------\n",
        "            # Save full transcript as TXT\n",
        "            # -------------------------------\n",
        "            with open(txt_path, \"w\", encoding=\"utf-8\") as f:\n",
        "                f.write(\" \".join(all_text))\n",
        "\n",
        "            print(f\"✅ Saved TXT → {txt_path}\")\n",
        "            print(f\"✅ Saved SRT → {srt_path}\")\n",
        "\n",
        "print(\"\\n🎉 All audio files processed successfully!\")\n",
        "print(\"📂 Output folder:\", output_root)\n"
      ],
      "metadata": {
        "id": "0ShaMXAzg8OT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#"
      ],
      "metadata": {
        "id": "CUYnt-_wxf0y"
      }
    }
  ]
}
